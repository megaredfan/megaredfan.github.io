---
type: post
title: 'k8s网络模型'
---

## k8s对网络连通性的约定

+ 所有的Pod之间可以在不使用NAT网络地址转换的情况下相互通信
+ 所有的Nodes之间可以在不使用NAT网络地址转换的情况下相互通信
+ 每个Pod自己看到的自己的ip和其他Pod看到的一致

## 同一个pod下的容器是如何通信的

每个pod拥有独立的ip，而同一个pod下的多个容器则共享用一个网络namespace，它们之间的通信可以直接使用localhost。而这个网络namespace的初始化是在pause容器（infra容器）当中初始化的，同一个pod下的其他容器都通过`–net=container:NAMEorID`的形式加入pause容器的网络namespace。

### network namespace

网络namespace是linux中提供网络资源隔离的机制，其包括网络设备、IP协议栈（IPv4和IPv6）、IP路由表、防火墙规则等等。linux同时也提供了veth的机制，使得不同的namespace之间也可以进行数据传输。

## 同一台node上的pod之间是如何通信的

默认情况下，容器的网络模式为bridge模式，即在宿主机上创建名为"docker0"的网桥，每个启动的pod都将自己的eth0网卡通过veth设备连接到宿主机的docker0网桥上。也就是说，对于每个pod来说，它的eth0网卡都是一个veth pair的一端，而另一端则连接在宿主机的docker0网桥上。

当一个pod向同一个node上的另一个pod发送数据时，数据包会通过自身的eth0网卡传递到veth pair的另一端，也就是宿主机的docker0网桥上。网桥在收到数据包时，则会根据数据包的目标MAC地址进行查询，确认目标是否是连接在自身的其他pod。当网桥发现了目标pod时，网桥就会把数据包转发到连接在自身的目标pod的veth pair，然后这些数据就会出现在目标pod的eth0网卡上了。具体示意图如下：
![img](/img/podonnode.png)

### veth 和 bridge

veth是linux系统中提供的一种在不同网络namespace之间通信的机制。当创建一个veth设备时，系统会返回两个互相连通的端点，称为veth pair。从任意一端发送的数据会被立刻传输到另一端上。

当一个veth pair连接到网桥上时，它就会变为网桥的一个“端口”，从端口传入的数据会由网桥处理，而网桥会判断数据包的转发或者丢弃，然后将数据包发送到某个端口上。

当docker0网桥被创建时，同时还会在系统的路由表中添加路由信息，指定将目标为该宿主机上的pod的数据包交给网桥处理。这样通过IP向宿主机上的pod发送数据时，数据就会交给网桥处理并转发到指定pod了。

### node上的进程到pod是如何通信的

根据前面提到的内容，node上的其他进程（比如agent）也可以通过ip向pod发送数据时，数据包也会先到达网桥，然后由网桥转发到对应的pod。

## 不同node上的pod之间是如何通信的

既然网桥可以处理同一宿主机上的不同pod，那么把所有node上的所有pod都连接到同一个网桥上就可以实现互相访问了。或者其实不一定要网桥，只要能够让宿主机直到如何转发pod发送的数据包就可以了，宿主机通过某种机制再转发到实际的pod就可以了。

### flannel

flannel是coreos提供的跨宿主机的容器网络方案的框架，而flannel目前提供三种后端实现：UDP、VXLAN和host gw。

flannel的工作原理就是在每台宿主机上部署一个agent进程（称为flanneld），flanneld负责在宿主机上配置各种路由信息，来协助宿主机判断数据包的转发目标。每台宿主机都由flanneld划分一个子网，具体的配置信息都存储在etcd中。子网划分的目的在于将同一宿主机上的pod都划给同一个子网，那么数据路由就可以以node为粒度，pod跨node通信时就可以先转发到node，再由node转发到pod。

#### UDP模式

UDP模式是最初的实现，但因为其性能等因素目前已经不建议采用了，但是却是最简单直观的方案。

当node1上的pod1根据ip向node2上的pod2上发送数据时，会发生以下的事情：

1. 数据会首先出现在node1的docker0网桥上
2. 由于node1的docker0并不处理发到pod2的数据，所以数据包会按照node1上配置的路由信息进行处理
3. flanneld会在node1上增加额外的路由信息，指定将发往pod2所在网段的数据转发到flannel0的设备上
4. flannel0实际上是一个TUN设备（Tunnel设备），它会将收到的数据包传递到flanneld进程
5. flanneld收到数据包后，发现是发给pod2的，于是根据其维护的路由信息将数据包转发到node2上的flanneld进程
6. node2上的flanneld进程收到数据包之后，再将数据发送到node2上的flannel0设备上
7. node2上的flannel0收到数据之后，会根据数据包的目标地址转发到docker0网桥上
8. docker0网桥收到数据后，将其转发到pod2的eth0上，数据包的传递就完成了

![flannel udp](/img/flannel_udp.png)
之所以叫UDP模式，是因为第5步中flanneld之间是通过UDP通信的，每个flanneld都监听指定端口（8285），而发送时则将数据发送到目标node的指定端口即可。这里使用UDP的原因，大概是因为网络层本来就不保证传输的可靠性，使用UDP更加简单直接，节省资源。

**TUN设备**

在linux中，TUN设备是一种工作在三层（Network Layer）的虚拟网络设备。TUN设备的功能就是在操作系统内核和用户应用程序之间传递IP包。

#### VXLAN

VXLAN 即Virtual Extensible LAN（虚拟可扩展局域网），是linux内核本身就支持的一种网络虚似化技术。所以说，VXLAN可以完全在内核态实现上述UDP模式封装和解封装的工作，从而通过与前面相似的“隧道”机制，构建出覆盖网络（Overlay Network）。

VXLAN的思路是在现有的三层（网络层）网络上增加一层虚拟的二层（数据链路层）网络，连接到这个虚拟的二层网络上的主机都可以像同一个局域网内的主机一样互相通信。为了让不同主机在这个虚拟的网络上连通，VXLAN在宿主机上创建了一种VTEP（VXLAN Tunnel Endpoint）设备。VTEP的作用实际上和UDP模式中的flanneld进程类似，都是将数据包进行封装和拆封。但是VTEP封装的对象是一个数据帧（对应数据链路层），整个逻辑都可以在内核态完成。

为了组成虚拟的局域网，发送端的VTEP设备需要将原始的IP数据包封装成一个二层网络的数据帧，所以需要知道目标VTEP设备的MAC地址。而这里的MAC地址则由flanneld进程维护，VTEP能够顺利地拿到目标MAC地址，并组装一个数据帧。随后这个数据帧会被添加一个VXLAN header标识，表明这是一个VXLAN数据帧，接收端在看到VXLAN header标识之后就能够判断应该将数据交给VTEP设备处理。随后这个携带了VXLAN header的数据帧就会被通过UDP发送到目标node上，同样，目标node的地址等信息也由flanneld维护。、

#### host gw模式
todo